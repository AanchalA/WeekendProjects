{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8Rhl0TqrJPLAE+AEkgbR2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AanchalA/WeekendProjects/blob/main/MNIST_with_VariationalAutoEncoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoEncoders to Variational AutoEncoders\n",
        "\n",
        "---\n",
        "- Modify Encoder graph: Replace bottleneck with gaussian distribution\n",
        "\n",
        "- Update Loss to = Î± (Reconstruction loss weight) * RMSE (Reconstruction loss) + KL Diverdence\n",
        "\n"
      ],
      "metadata": {
        "id": "tnA46Vhrt0Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, ReLU, BatchNormalization, Flatten,\n",
        "    Dense, Reshape, Conv2DTranspose, Activation, Lambda)\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "JJT--mRnB8K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_reconstruction_loss(y_target, y_predicted):\n",
        "    error = y_target - y_predicted\n",
        "    reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
        "    return reconstruction_loss\n",
        "\n",
        "\n",
        "def calculate_kl_loss(model):\n",
        "    # wrap `_calculate_kl_loss` such that it takes the model as an argument,\n",
        "    # returns a function which can take arbitrary number of arguments\n",
        "    # (for compatibility with `metrics` and utility in the loss function)\n",
        "    # and returns the kl loss\n",
        "    def _calculate_kl_loss(*args):\n",
        "        kl_loss = -0.5 * K.sum(1 + model.log_variance - K.square(model.mean_vector) -\n",
        "                               K.exp(model.log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    return _calculate_kl_loss"
      ],
      "metadata": {
        "id": "61rWd4R5CAQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VariationalAutoEncoder:\n",
        "    \"\"\"\n",
        "    VariationalAutoEncoder represents a Deep Convolutional Variational Autoencoder architecture with\n",
        "    mirrored encoder and decoder components\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_shape,\n",
        "                 conv_filters,\n",
        "                 conv_kernels,\n",
        "                 conv_strides,\n",
        "                 latent_space_dim):\n",
        "\n",
        "        self.input_shape = input_shape  # [28, 28, 1] - [width in pixel, height in pixel, num_channels]\n",
        "        self.conv_filters = conv_filters  # [2, 4, 8] - Number of conv filters per layer\n",
        "        self.conv_kernels = conv_kernels  # [3, 5, 3] - Kernel size per layer [3x3, 5x5, 3x3]\n",
        "        self.conv_strides = conv_strides  # [1, 2, 2] - Strides per layer\n",
        "        self.latent_space_dim = latent_space_dim  # 2 - Number of units in the Bottleneck layer\n",
        "\n",
        "        self.model = None\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self._model_input = None\n",
        "        self._shape_before_bottleneck = None\n",
        "        self.reconstruction_loss_weight = 1000\n",
        "        self._num_conv_layers = len(conv_filters)  # Private Attribute\n",
        "        self._build()\n",
        "\n",
        "    def _build(self):\n",
        "        \"\"\"\n",
        "        Method to build the encoder, the decoder and the model\n",
        "        \"\"\"\n",
        "        self._build_encoder()\n",
        "        self._build_decoder()\n",
        "        self._build_autoencoder()\n",
        "\n",
        "    def _build_encoder(self):\n",
        "        encoder_input = self._add_encoder_input()\n",
        "        self._model_input = encoder_input\n",
        "        conv_layers = self._add_conv_layers(encoder_input)\n",
        "        bottleneck = self._add_bottleneck(conv_layers)  # Bottleneck - Latent Space: Encoder o/p\n",
        "        self.encoder = Model(encoder_input, bottleneck, name='encoder')\n",
        "\n",
        "    def _add_encoder_input(self):\n",
        "        return Input(shape=self.input_shape, name='encoder_input')\n",
        "\n",
        "    def _add_conv_layers(self, encoder_input):\n",
        "        \"\"\"\n",
        "        Creates all convolutional blocks in the encoder.\n",
        "        \"\"\"\n",
        "        x = encoder_input\n",
        "        for layer_index in range(self._num_conv_layers):\n",
        "            x = self._add_conv_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_layer(self, layer_index, x):\n",
        "        \"\"\"\n",
        "        x = Graph of layers\n",
        "        Adds a convolutional block to a graph of layers.\n",
        "        The convolutional block consists of - Conv2D, ReLU, Batch Normalization\n",
        "        \"\"\"\n",
        "        layer_number = layer_index + 1\n",
        "        conv_layer = Conv2D(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding='same',\n",
        "            name=f'encoder_conv_layer_{layer_number}'\n",
        "        )\n",
        "        x = conv_layer(x)\n",
        "        x = ReLU(name=f'encoder_relu_{layer_number}')(x)\n",
        "        x = BatchNormalization(name=f'encoder_bn_{layer_number}')(x)\n",
        "        return x\n",
        "\n",
        "    def _add_bottleneck(self, x):\n",
        "        \"\"\"\n",
        "        Flatten data and add bottleneck with Gaussian Sampling (Dense Layer).\n",
        "        \"\"\"\n",
        "        self._shape_before_bottleneck = K.int_shape(x)[\n",
        "                                        1:]  # K.int_shape(x) -- [batch size, width, height, num_channels]\n",
        "        x = Flatten()(x)\n",
        "        self.mean_vector = Dense(units=self.latent_space_dim, name='encoder_mean_vector')(x)\n",
        "        self.log_variance = Dense(units=self.latent_space_dim, name='encoder_log_variance_vector')(x)\n",
        "\n",
        "        def sample_point_from_normal_distribution(args):\n",
        "            mean_vector, log_variance = args\n",
        "            epsilon = K.random_normal(shape=K.shape(self.mean_vector), mean=0., stddev=1.)\n",
        "            sampled_point = mean_vector + K.exp(log_variance / 2) * epsilon\n",
        "            return sampled_point\n",
        "\n",
        "        x = Lambda(sample_point_from_normal_distribution,\n",
        "                   name='encoder_output')([self.mean_vector, self.log_variance])\n",
        "        return x\n",
        "\n",
        "    def _build_decoder(self):\n",
        "        decoder_input = self._add_decoder_input()\n",
        "        dense_layer = self._add_dense_layer(decoder_input)\n",
        "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
        "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
        "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
        "        self.decoder = Model(decoder_input, decoder_output, name='decoder')\n",
        "\n",
        "    def _add_decoder_input(self):\n",
        "        return Input(shape=self.latent_space_dim, name='decoder_input')\n",
        "\n",
        "    def _add_dense_layer(self, decoder_input):\n",
        "        # He used np.prod instead of Flatten here because he wanted to calculate the number of units for the dense\n",
        "        # layer based on the shape of the encoder output. np.prod is a numpy function that returns the product of all\n",
        "        # elements in an array. Flatten is a Keras layer that converts a multidimensional tensor into a\n",
        "        # one-dimensional vector. He did not need to flatten the encoder output here, he just needed to know its size.\n",
        "        num_neurons = np.prod(self._shape_before_bottleneck)  # Need to get the count of flattened units\n",
        "        dense_layer = Dense(num_neurons, name='decoder_dense')(decoder_input)\n",
        "        return dense_layer\n",
        "\n",
        "    def _add_reshape_layer(self, dense_layer):\n",
        "        return Reshape(target_shape=self._shape_before_bottleneck)(dense_layer)\n",
        "\n",
        "    def _add_conv_transpose_layers(self, x):\n",
        "        \"\"\"\n",
        "        Add all convolutional transpose blocks in the decoder.\n",
        "        Loop through all the convolutional layers in reverse order and stop at the first layer\n",
        "        \"\"\"\n",
        "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
        "            x = self._add_conv_transpose_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_transpose_layer(self, layer_index, x):\n",
        "        \"\"\"\n",
        "        x = Graph of layers\n",
        "        Adds a convolutional transpose block to a graph of layers.\n",
        "        The convolutional transpose block consists of - Conv2DTranspose, ReLU, Batch Normalization\n",
        "        \"\"\"\n",
        "        layer_num = self._num_conv_layers - layer_index\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding='same',\n",
        "            name=f'decoder_conv_transpose_layer_{layer_num}'\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        x = ReLU(name=f'decoder_relu_{layer_num}')(x)\n",
        "        x = BatchNormalization(name=f'decoder_bn_{layer_num}')(x)\n",
        "        return x\n",
        "\n",
        "    def _add_decoder_output(self, x):\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=1,  # Corresponds to num_channels\n",
        "            kernel_size=self.conv_kernels[0],\n",
        "            strides=self.conv_strides[0],\n",
        "            padding='same',\n",
        "            name=f'decoder_conv_transpose_layer_{self._num_conv_layers}'\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        output_layer = Activation(activation='sigmoid', name='sigmoid_layer')(x)\n",
        "        return output_layer\n",
        "\n",
        "    def _build_autoencoder(self):\n",
        "        model_input = self._model_input\n",
        "        model_output = self.decoder(self.encoder(model_input))\n",
        "        self.model = Model(model_input, model_output, name='autoencoder')\n",
        "\n",
        "    # def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
        "    #     error = y_target - y_predicted\n",
        "    #     reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
        "    #     return reconstruction_loss\n",
        "    #\n",
        "    # def _calculate_kl_loss(self, y_target, y_predicted):\n",
        "    #     kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mean_vector) - K.exp(self.log_variance), axis=1)\n",
        "    #     return kl_loss\n",
        "\n",
        "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
        "        reconstruction_loss = calculate_reconstruction_loss(y_target, y_predicted)\n",
        "        kl_loss = calculate_kl_loss(self)()\n",
        "        # kl_loss = calculate_kl_loss(y_target, y_predicted)\n",
        "        combined_loss = self.reconstruction_loss_weight + reconstruction_loss + kl_loss\n",
        "        return combined_loss\n",
        "\n",
        "    def summary(self):\n",
        "        self.encoder.summary()\n",
        "        self.decoder.summary()\n",
        "        self.model.summary()\n",
        "\n",
        "    def compile(self, learning_rate=0.0001):\n",
        "        # optimizer = Adam(learning_rate=learning_rate)\n",
        "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
        "        self.model.compile(optimizer=optimizer,\n",
        "                           loss=self._calculate_combined_loss,\n",
        "                           metrics=[calculate_reconstruction_loss,\n",
        "                                    calculate_kl_loss(self)])\n",
        "\n",
        "    def train(self, x_train, batch_size, num_epochs):\n",
        "        NAME = f'auto-encoder-{int(time.time())}'\n",
        "        tensorboard = TensorBoard(log_dir=f'logs/{NAME}')\n",
        "        self.model.fit(x_train,\n",
        "                       x_train,\n",
        "                       shuffle=True,\n",
        "                       epochs=num_epochs,\n",
        "                       batch_size=batch_size,\n",
        "                       callbacks=[tensorboard]\n",
        "                       )\n",
        "\n",
        "    def save(self, save_folder='.'):\n",
        "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
        "        self._save_parameters(save_folder)\n",
        "        self._save_weights(save_folder)\n",
        "\n",
        "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "\n",
        "    def _save_parameters(self, save_folder):\n",
        "        parameters = [\n",
        "            self.input_shape,\n",
        "            self.conv_filters,\n",
        "            self.conv_kernels,\n",
        "            self.conv_strides,\n",
        "            self.latent_space_dim\n",
        "        ]\n",
        "        save_path = os.path.join(save_folder, 'parameters.pkl')\n",
        "        with open(save_path, 'wb') as f:\n",
        "            pickle.dump(parameters, f)\n",
        "\n",
        "    def _save_weights(self, save_folder):\n",
        "        save_path = os.path.join(save_folder, 'weights.h5')\n",
        "        self.model.save_weights(save_path)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, save_folder='.'):\n",
        "\n",
        "        parameters_path = os.path.join(save_folder, 'parameters.pkl')\n",
        "        with open(parameters_path, 'rb') as f:\n",
        "            parameters = pickle.load(f)\n",
        "\n",
        "        autoencoder = VariationalAutoEncoder(*parameters)\n",
        "        weights_path = os.path.join(save_folder, 'weights.h5')\n",
        "        autoencoder.load_weights(weights_path)\n",
        "        return autoencoder\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        self.model.load_weights(weights_path)\n",
        "\n",
        "    def reconstruct(self, images):\n",
        "        latent_representation = self.encoder.predict(images)\n",
        "        reconstructed_images = self.decoder(latent_representation)\n",
        "        return reconstructed_images, latent_representation"
      ],
      "metadata": {
        "id": "DaNYtP2A0yHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# autoencoder = VariationalAutoEncoder(\n",
        "#     input_shape=(28, 28, 1),\n",
        "#     conv_filters=(32, 64, 64, 64),\n",
        "#     conv_kernels=(3, 3, 3, 3),\n",
        "#     conv_strides=(1, 2, 2, 1),\n",
        "#     latent_space_dim=2\n",
        "# )\n",
        "# autoencoder.summary()"
      ],
      "metadata": {
        "id": "083-KYowFQv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from variational_autoencoder import VariationalAutoEncoder\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "\n",
        "def load_mnist():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    # x_train = x_train.reshape((*x_train.shape, 1))\n",
        "    x_train = x_train.reshape(x_train.shape + (1, ))\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "    # x_test = x_test.reshape((*x_test.shape, 1))\n",
        "    x_test = x_test.reshape(x_test.shape + (1, ))\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "def train(x_train, learning_rate, batch_size, epochs):\n",
        "    autoencoder = VariationalAutoEncoder(\n",
        "        input_shape=(28, 28, 1),\n",
        "        conv_filters=(32, 64, 64, 64),\n",
        "        conv_kernels=(3, 3, 3, 3),\n",
        "        conv_strides=(1, 2, 2, 1),\n",
        "        latent_space_dim=2\n",
        "    )\n",
        "    # autoencoder.summary()\n",
        "    autoencoder.compile(learning_rate),\n",
        "    autoencoder.train(x_train, batch_size, epochs)\n",
        "    return autoencoder\n",
        "\n",
        "x_train, _, _, _ = load_mnist()\n",
        "autoencoder = train(x_train[:10000], LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
        "autoencoder.save('model')"
      ],
      "metadata": {
        "id": "f7qLBBlRKU0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8e2f1b-ab46-4a9b-9fb1-be4a05689650"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 10000 samples\n",
            "Epoch 1/50\n",
            "10000/10000 [==============================] - 73s 7ms/sample - loss: 1000.4495 - calculate_reconstruction_loss: 0.0957 - _calculate_kl_loss: 0.3539\n",
            "Epoch 2/50\n",
            "10000/10000 [==============================] - 71s 7ms/sample - loss: 1000.1153 - calculate_reconstruction_loss: 0.0723 - _calculate_kl_loss: 0.0431\n",
            "Epoch 3/50\n",
            "10000/10000 [==============================] - 68s 7ms/sample - loss: 1000.0940 - calculate_reconstruction_loss: 0.0697 - _calculate_kl_loss: 0.0242\n",
            "Epoch 4/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0867 - calculate_reconstruction_loss: 0.0696 - _calculate_kl_loss: 0.0172\n",
            "Epoch 5/50\n",
            "10000/10000 [==============================] - 70s 7ms/sample - loss: 1000.0810 - calculate_reconstruction_loss: 0.0689 - _calculate_kl_loss: 0.0122\n",
            "Epoch 6/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0856 - calculate_reconstruction_loss: 0.0692 - _calculate_kl_loss: 0.0164\n",
            "Epoch 7/50\n",
            "10000/10000 [==============================] - 68s 7ms/sample - loss: 1000.0818 - calculate_reconstruction_loss: 0.0688 - _calculate_kl_loss: 0.0130\n",
            "Epoch 8/50\n",
            "10000/10000 [==============================] - 71s 7ms/sample - loss: 1000.0765 - calculate_reconstruction_loss: 0.0686 - _calculate_kl_loss: 0.0079\n",
            "Epoch 9/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0759 - calculate_reconstruction_loss: 0.0684 - _calculate_kl_loss: 0.0075\n",
            "Epoch 10/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0759 - calculate_reconstruction_loss: 0.0680 - _calculate_kl_loss: 0.0078\n",
            "Epoch 11/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0746 - calculate_reconstruction_loss: 0.0676 - _calculate_kl_loss: 0.0069\n",
            "Epoch 12/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0742 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0067\n",
            "Epoch 13/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0743 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0069\n",
            "Epoch 14/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0716 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0041\n",
            "Epoch 15/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0734 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0059\n",
            "Epoch 16/50\n",
            "10000/10000 [==============================] - 65s 7ms/sample - loss: 1000.0743 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0069\n",
            "Epoch 17/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0726 - calculate_reconstruction_loss: 0.0675 - _calculate_kl_loss: 0.0051\n",
            "Epoch 18/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0737 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0063\n",
            "Epoch 19/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0727 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0053\n",
            "Epoch 20/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0716 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0042\n",
            "Epoch 21/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0725 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0051\n",
            "Epoch 22/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0718 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0044\n",
            "Epoch 23/50\n",
            "10000/10000 [==============================] - 65s 7ms/sample - loss: 1000.0718 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0044\n",
            "Epoch 24/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0736 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0062\n",
            "Epoch 25/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0721 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0047\n",
            "Epoch 26/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0708 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0034\n",
            "Epoch 27/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0707 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0033\n",
            "Epoch 28/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0705 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0031\n",
            "Epoch 29/50\n",
            "10000/10000 [==============================] - 65s 7ms/sample - loss: 1000.0730 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0056\n",
            "Epoch 30/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0741 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0067\n",
            "Epoch 31/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0701 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0027\n",
            "Epoch 32/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0712 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0038\n",
            "Epoch 33/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0720 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0045\n",
            "Epoch 34/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0732 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0058\n",
            "Epoch 35/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.2519 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.1845\n",
            "Epoch 36/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0804 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0130\n",
            "Epoch 37/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0744 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0070\n",
            "Epoch 38/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0789 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0115\n",
            "Epoch 39/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0830 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0156\n",
            "Epoch 40/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0707 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0033\n",
            "Epoch 41/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0706 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0032\n",
            "Epoch 42/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0783 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0109\n",
            "Epoch 43/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0749 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0075\n",
            "Epoch 44/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0753 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0080\n",
            "Epoch 45/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0688 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0015\n",
            "Epoch 46/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0775 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0101\n",
            "Epoch 47/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.0825 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0151\n",
            "Epoch 48/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.1005 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0331\n",
            "Epoch 49/50\n",
            "10000/10000 [==============================] - 66s 7ms/sample - loss: 1000.0715 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0041\n",
            "Epoch 50/50\n",
            "10000/10000 [==============================] - 67s 7ms/sample - loss: 1000.1064 - calculate_reconstruction_loss: 0.0674 - _calculate_kl_loss: 0.0390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model\n",
        "loaded_autoencoder = VariationalAutoEncoder.load('model')\n",
        "loaded_autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNk8AO-thxVk",
        "outputId": "8245fdaa-3a15-4cc7-ffc9-87332d7dca4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " encoder_conv_layer_1 (Conv2D)  (None, 28, 28, 32)   320         ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_relu_1 (ReLU)          (None, 28, 28, 32)   0           ['encoder_conv_layer_1[0][0]']   \n",
            "                                                                                                  \n",
            " encoder_bn_1 (BatchNormalizati  (None, 28, 28, 32)  128         ['encoder_relu_1[0][0]']         \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_conv_layer_2 (Conv2D)  (None, 14, 14, 64)   18496       ['encoder_bn_1[0][0]']           \n",
            "                                                                                                  \n",
            " encoder_relu_2 (ReLU)          (None, 14, 14, 64)   0           ['encoder_conv_layer_2[0][0]']   \n",
            "                                                                                                  \n",
            " encoder_bn_2 (BatchNormalizati  (None, 14, 14, 64)  256         ['encoder_relu_2[0][0]']         \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_conv_layer_3 (Conv2D)  (None, 7, 7, 64)     36928       ['encoder_bn_2[0][0]']           \n",
            "                                                                                                  \n",
            " encoder_relu_3 (ReLU)          (None, 7, 7, 64)     0           ['encoder_conv_layer_3[0][0]']   \n",
            "                                                                                                  \n",
            " encoder_bn_3 (BatchNormalizati  (None, 7, 7, 64)    256         ['encoder_relu_3[0][0]']         \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_conv_layer_4 (Conv2D)  (None, 7, 7, 64)     36928       ['encoder_bn_3[0][0]']           \n",
            "                                                                                                  \n",
            " encoder_relu_4 (ReLU)          (None, 7, 7, 64)     0           ['encoder_conv_layer_4[0][0]']   \n",
            "                                                                                                  \n",
            " encoder_bn_4 (BatchNormalizati  (None, 7, 7, 64)    256         ['encoder_relu_4[0][0]']         \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 3136)         0           ['encoder_bn_4[0][0]']           \n",
            "                                                                                                  \n",
            " encoder_mean_vector (Dense)    (None, 2)            6274        ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " encoder_log_variance_vector (D  (None, 2)           6274        ['flatten_1[0][0]']              \n",
            " ense)                                                                                            \n",
            "                                                                                                  \n",
            " encoder_output (Lambda)        (None, 2)            0           ['encoder_mean_vector[0][0]',    \n",
            "                                                                  'encoder_log_variance_vector[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,116\n",
            "Trainable params: 105,668\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " decoder_dense (Dense)       (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decoder_conv_transpose_laye  (None, 7, 7, 64)         36928     \n",
            " r_1 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " decoder_relu_1 (ReLU)       (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decoder_bn_1 (BatchNormaliz  (None, 7, 7, 64)         256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " decoder_conv_transpose_laye  (None, 14, 14, 64)       36928     \n",
            " r_2 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " decoder_relu_2 (ReLU)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " decoder_bn_2 (BatchNormaliz  (None, 14, 14, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " decoder_conv_transpose_laye  (None, 28, 28, 64)       36928     \n",
            " r_3 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " decoder_relu_3 (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " decoder_bn_3 (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " decoder_conv_transpose_laye  (None, 28, 28, 1)        577       \n",
            " r_4 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " sigmoid_layer (Activation)  (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,537\n",
            "Trainable params: 121,153\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " encoder (Functional)        (None, 2)                 106116    \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 28, 28, 1)         121537    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227,653\n",
            "Trainable params: 226,821\n",
            "Non-trainable params: 832\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from train import load_mnist\n",
        "# from variational_autoencoder import VariationalAutoEncoder\n",
        "\n",
        "def select_images(images, labels, num_images=10):\n",
        "    sample_images_index = np.random.choice(range(len(images)), num_images)\n",
        "    sample_images = images[sample_images_index]\n",
        "    sample_labels = labels[sample_images_index]\n",
        "    return sample_images, sample_labels\n",
        "\n",
        "\n",
        "def plot_reconstructed_images(images, reconstructed_images):\n",
        "    fig = plt.figure(figsize=(15, 3))\n",
        "    num_images = len(images)\n",
        "    for i, (image, reconstructed_image) in enumerate(zip(images, reconstructed_images)):\n",
        "        image = image.squeeze()\n",
        "        ax = fig.add_subplot(2, num_images, i + 1)\n",
        "        ax.axis(\"off\")\n",
        "        ax.imshow(image, cmap=\"gray_r\")\n",
        "        # reconstructed_image = reconstructed_image.squeeze()\n",
        "        reconstructed_image = np.squeeze(reconstructed_image)\n",
        "        ax = fig.add_subplot(2, num_images, i + num_images + 1)\n",
        "        ax.axis(\"off\")\n",
        "        ax.imshow(reconstructed_image, cmap=\"gray_r\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_images_encoded_in_latent_space(latent_representations, sample_labels):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.scatter(latent_representations[:, 0],\n",
        "                latent_representations[:, 1],\n",
        "                cmap=\"rainbow\",\n",
        "                c=sample_labels,\n",
        "                alpha=0.5,\n",
        "                s=2)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "autoencoder = VariationalAutoEncoder.load(\"model\")\n",
        "x_train, y_train, x_test, y_test = load_mnist()\n",
        "\n",
        "num_sample_images_to_show = 8\n",
        "sample_images, _ = select_images(x_test, y_test, num_sample_images_to_show)\n",
        "reconstructed_images, _ = autoencoder.reconstruct(sample_images)\n",
        "plot_reconstructed_images(sample_images, reconstructed_images)\n",
        "\n",
        "num_images = 6000\n",
        "sample_images, sample_labels = select_images(x_test, y_test, num_images)\n",
        "_, latent_representations = autoencoder.reconstruct(sample_images)\n",
        "plot_images_encoded_in_latent_space(latent_representations, sample_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "M5F_uRbgkvRf",
        "outputId": "0546a90b-28bb-4867-8b02-f04fbb9c931f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OperatorNotAllowedInGraphError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b1018d33767c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0msample_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sample_images_to_show\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mreconstructed_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mplot_reconstructed_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b1018d33767c>\u001b[0m in \u001b[0;36mplot_reconstructed_images\u001b[0;34m(images, reconstructed_images)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_image\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iterating over a symbolic `tf.Tensor`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;34mf\"{task} is not allowed in Graph execution. Use Eager execution or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \" decorate this function with @tf.function.\")\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: Iterating over a symbolic `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x216 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}